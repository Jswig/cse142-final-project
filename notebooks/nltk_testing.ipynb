{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Only needs to be run once to create a csv file for the training data\n",
    "\n",
    "# set path to file\n",
    "# p = Path(r'C:\\Users\\anish\\Desktop\\cse142_nltk\\data_train.json')\n",
    "\n",
    "\n",
    "# # read json\n",
    "# with p.open('r', encoding='utf-8') as f:\n",
    "#     data = json.loads(f.read())\n",
    "\n",
    "# # create dataframe\n",
    "# df = json_normalize(data)\n",
    "# # create dataframe\n",
    "# df = json_normalize(data)\n",
    "# # save to csv\n",
    "# df.to_csv('data_train.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  Total bill for this horrible service? Over $8G...\n",
      "1  I *adore* Travis at the Hard Rock's new Kelly ...\n",
      "2  I have to say that this office really has it t...\n",
      "3  Went in for a lunch. Steak sandwich was delici...\n",
      "4  Today was my second out of three sessions I ha...\n"
     ]
    }
   ],
   "source": [
    "# extract stars/ratings column. Will be used later when \n",
    "# extract text column since that is what we'll be using\n",
    "df = pd.read_csv(\"data_train.csv\")\n",
    "ratings = df['stars'].values.tolist()\n",
    "textdf = df.drop(['stars' ,'useful', 'funny','cool', 'date'], axis=1)\n",
    "print(textdf.head())\n",
    "total = len(textdf[\"text\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count for every review\n",
    "text_len = []\n",
    "for index, row in textdf.iterrows():\n",
    "    text_len.append(len(row[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>3509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  word_count\n",
       "0  Total bill for this horrible service? Over $8G...         204\n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...        1561\n",
       "2  I have to say that this office really has it t...         615\n",
       "3  Went in for a lunch. Steak sandwich was delici...         407\n",
       "4  Today was my second out of three sessions I ha...        3509"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf['word_count'] = text_len\n",
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "words = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total bill horrible service? $8gs. crooks actually nerve charge us $69 3 pills. checked online pills 19 cents each! avoid hospital ers costs.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase words in review and remove stopwords\n",
    "review_list = []\n",
    "for index, row in textdf.iterrows():\n",
    "    temp = row[\"text\"].split()\n",
    "    temp2 = [word.lower() for word in temp if word.lower() not in words]\n",
    "    review = \" \".join(word for word in temp2)\n",
    "    review_list.append(review)\n",
    "review_list[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 17]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentence_count = []\n",
    "for index, row in textdf.iterrows():\n",
    "    num_of_sent = sent_tokenize(row[\"text\"])\n",
    "    sentence_count.append(len(num_of_sent))\n",
    "print(sentence_count[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_stopwords_punc_reviews</th>\n",
       "      <th>final_clean</th>\n",
       "      <th>lemmatized_review</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>204</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "      <td>total bill horrible service 8gs crook actually...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>1561</td>\n",
       "      <td>adore travis hard rocks new kelly cardenas sal...</td>\n",
       "      <td>adore travis hard rocks new kelly cardenas sal...</td>\n",
       "      <td>adore travis hard rock new kelly cardenas salo...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>615</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>407</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>3509</td>\n",
       "      <td>today second three sessions paid for although ...</td>\n",
       "      <td>today second three sessions paid for although ...</td>\n",
       "      <td>today second three session paid for although f...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  word_count  \\\n",
       "0  Total bill for this horrible service? Over $8G...         204   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...        1561   \n",
       "2  I have to say that this office really has it t...         615   \n",
       "3  Went in for a lunch. Steak sandwich was delici...         407   \n",
       "4  Today was my second out of three sessions I ha...        3509   \n",
       "\n",
       "                        clean_stopwords_punc_reviews  \\\n",
       "0  total bill horrible service 8gs crooks actuall...   \n",
       "1  adore travis hard rocks new kelly cardenas sal...   \n",
       "2  say office really together organized friendly ...   \n",
       "3  went lunch steak sandwich delicious caesar sal...   \n",
       "4  today second three sessions paid for although ...   \n",
       "\n",
       "                                         final_clean  \\\n",
       "0  total bill horrible service 8gs crooks actuall...   \n",
       "1  adore travis hard rocks new kelly cardenas sal...   \n",
       "2  say office really together organized friendly ...   \n",
       "3  went lunch steak sandwich delicious caesar sal...   \n",
       "4  today second three sessions paid for although ...   \n",
       "\n",
       "                                   lemmatized_review  sentence_count  \n",
       "0  total bill horrible service 8gs crook actually...               5  \n",
       "1  adore travis hard rock new kelly cardenas salo...              17  \n",
       "2  say office really together organized friendly ...               5  \n",
       "3  went lunch steak sandwich delicious caesar sal...               9  \n",
       "4  today second three session paid for although f...              29  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf['sentence_count'] = sentence_count\n",
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total bill horrible service 8gs crooks actually nerve charge us 69 3 pills checked online pills 19 cents each avoid hospital ers costs', 'adore travis hard rocks new kelly cardenas salon im always fan great blowout stranger chains offer service however travis taken flawless blowout whole new level traviss greets perfectly green swoosh otherwise perfectly styled black hair vegasworthy rockstar outfit next comes relaxing incredible shampoo  get full head message could cure even worst migraine minutes  scented shampoo room travis freakishly strong fingers in good way use perfect amount pressure superb starts glorious blowout one two three people involved best roundbrush action hair ever seen team stylists clearly gets along extremely well evident way talk help one another really genuine corporate requirement much fun there next travis started flat iron way flipped wrist get volume around without overdoing making look like texas pagent girl admirable also worth noting fry hair  something ive happen less skilled stylists end blowout  style hair perfectly bouncey looked terrific thing better awesome blowout lasted days travis see every single time im vegas make feel beauuuutiful']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# removes all punctuation from reviews\n",
    "import string\n",
    "clean_review = []\n",
    "for review in review_list:\n",
    "    clean_review.append(review.translate(str.maketrans('', '', string.punctuation)))\n",
    "print(clean_review[:2])\n",
    "textdf['clean_stopwords_punc_reviews'] = clean_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food       171013\n",
       "good       161099\n",
       "place      160453\n",
       "great      143014\n",
       "service    119359\n",
       "like       116287\n",
       "time       113930\n",
       "get        108899\n",
       "one        106897\n",
       "would      100492\n",
       "back        98733\n",
       "go          86714\n",
       "really      84101\n",
       "also        71608\n",
       "us          68329\n",
       "it          65544\n",
       "got         64238\n",
       "even        63441\n",
       "nice        59916\n",
       "well        59233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 occuring words across all cleaned reviews to see what I could further remove\n",
    "pd.Series(\" \".join(textdf['clean_stopwords_punc_reviews']).split()).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more preprocessing to remove words that have no meaning\n",
    "more_stopwords = [\"us\",\"im\",\"ive\",\"it\",\"get\"]\n",
    "final_clean = []\n",
    "for index, row in textdf.iterrows():\n",
    "    temp = row[\"clean_stopwords_punc_reviews\"].split()\n",
    "    temp2 = [word for word in temp if word not in more_stopwords]\n",
    "    clean_review = \" \".join(word for word in temp2)\n",
    "    final_clean.append(clean_review)\n",
    "textdf['final_clean'] = final_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_stopwords_punc_reviews</th>\n",
       "      <th>final_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>204</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>1561</td>\n",
       "      <td>adore travis hard rocks new kelly cardenas sal...</td>\n",
       "      <td>adore travis hard rocks new kelly cardenas sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>615</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>407</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>3509</td>\n",
       "      <td>today second three sessions paid for although ...</td>\n",
       "      <td>today second three sessions paid for although ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  word_count  \\\n",
       "0  Total bill for this horrible service? Over $8G...         204   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...        1561   \n",
       "2  I have to say that this office really has it t...         615   \n",
       "3  Went in for a lunch. Steak sandwich was delici...         407   \n",
       "4  Today was my second out of three sessions I ha...        3509   \n",
       "\n",
       "                        clean_stopwords_punc_reviews  \\\n",
       "0  total bill horrible service 8gs crooks actuall...   \n",
       "1  adore travis hard rocks new kelly cardenas sal...   \n",
       "2  say office really together organized friendly ...   \n",
       "3  went lunch steak sandwich delicious caesar sal...   \n",
       "4  today second three sessions paid for although ...   \n",
       "\n",
       "                                         final_clean  \n",
       "0  total bill horrible service 8gs crooks actuall...  \n",
       "1  adore travis hard rocks new kelly cardenas sal...  \n",
       "2  say office really together organized friendly ...  \n",
       "3  went lunch steak sandwich delicious caesar sal...  \n",
       "4  today second three sessions paid for although ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a lemmatized version of reviews\n",
    "lemmatized_reviews = []\n",
    "for index, row in textdf.iterrows():\n",
    "    temp = row[\"final_clean\"].split()\n",
    "    temp2 = [Word(word).lemmatize() for word in temp]\n",
    "    lemmatized_review = \" \".join(word for word in temp2)\n",
    "    lemmatized_reviews.append(lemmatized_review)\n",
    "textdf['lemmatized_review'] = lemmatized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_stopwords_punc_reviews</th>\n",
       "      <th>final_clean</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>204</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "      <td>total bill horrible service 8gs crook actually...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>1561</td>\n",
       "      <td>adore travis hard rocks new kelly cardenas sal...</td>\n",
       "      <td>adore travis hard rocks new kelly cardenas sal...</td>\n",
       "      <td>adore travis hard rock new kelly cardenas salo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>615</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>407</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>3509</td>\n",
       "      <td>today second three sessions paid for although ...</td>\n",
       "      <td>today second three sessions paid for although ...</td>\n",
       "      <td>today second three session paid for although f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  word_count  \\\n",
       "0  Total bill for this horrible service? Over $8G...         204   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...        1561   \n",
       "2  I have to say that this office really has it t...         615   \n",
       "3  Went in for a lunch. Steak sandwich was delici...         407   \n",
       "4  Today was my second out of three sessions I ha...        3509   \n",
       "\n",
       "                        clean_stopwords_punc_reviews  \\\n",
       "0  total bill horrible service 8gs crooks actuall...   \n",
       "1  adore travis hard rocks new kelly cardenas sal...   \n",
       "2  say office really together organized friendly ...   \n",
       "3  went lunch steak sandwich delicious caesar sal...   \n",
       "4  today second three sessions paid for although ...   \n",
       "\n",
       "                                         final_clean  \\\n",
       "0  total bill horrible service 8gs crooks actuall...   \n",
       "1  adore travis hard rocks new kelly cardenas sal...   \n",
       "2  say office really together organized friendly ...   \n",
       "3  went lunch steak sandwich delicious caesar sal...   \n",
       "4  today second three sessions paid for although ...   \n",
       "\n",
       "                                   lemmatized_review  \n",
       "0  total bill horrible service 8gs crook actually...  \n",
       "1  adore travis hard rock new kelly cardenas salo...  \n",
       "2  say office really together organized friendly ...  \n",
       "3  went lunch steak sandwich delicious caesar sal...  \n",
       "4  today second three session paid for although f...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3333333333333333, 204, 5], [0.3301852559205501, 1561, 17]]\n"
     ]
    }
   ],
   "source": [
    "# Loops through all rows and calculates polarity for each lemmatized review\n",
    "sentiment_list = []\n",
    "for index, row in textdf.iterrows():\n",
    "    sentiment_list.append([TextBlob(row[\"lemmatized_review\"]).sentiment[0],row[\"word_count\"],row[\"sentence_count\"]] )\n",
    "print(sentiment_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20625000000000002, 436, 7], [0.07361111111111113, 485, 7]]\n",
      "[[0.0, 87, 3], [0.0, 217, 4]]\n"
     ]
    }
   ],
   "source": [
    "# split data into test and training for experimental purposes to see logisitc regression accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_list, ratings, test_size=0.2)\n",
    "print(X_train[:2])\n",
    "print(X_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.  87.   3.]\n",
      " [  0. 217.   4.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# convert array to numpy array for fit function and fit model\n",
    "sentiments = np.asarray(X_test)\n",
    "print(sentiments[:2])\n",
    "clf = LogisticRegression(multi_class='auto',solver='lbfgs', max_iter=1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 5., 5., 1., 5., 5., 5., 5., 1., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       1., 1., 1., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 1., 5., 5., 4.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 1., 1., 5.,\n",
       "       5., 4., 4., 5., 5., 5., 1., 5., 5., 5., 1., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 1., 5., 5., 5., 1., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 4., 1., 5., 1., 5., 5., 5., 5., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicts rating for test set\n",
    "clf.predict(sentiments[:100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5287994136915001"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy on test set\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
