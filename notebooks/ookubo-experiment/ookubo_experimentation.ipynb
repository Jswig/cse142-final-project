{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDwfmQ5qXwA5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
    "import pandas as pd\n",
    "from pandas import get_dummies\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9ck_IsiX-_a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d793cad0925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load in JSON files and extract from JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreviews_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_LOC\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFILE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_train.json'"
     ]
    }
   ],
   "source": [
    "DATA_LOC = 'data/'\n",
    "FILE_NAME = 'data_train.json'\n",
    "\n",
    "# Load in JSON files and extract from JSON\n",
    "reviews_json = open(DATA_LOC + FILE_NAME, 'r')\n",
    "reviews = json.load(reviews_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gkxFimOYxkt"
   },
   "outputs": [],
   "source": [
    "# Analyze the distribution of stars and reviews as seperate lists\n",
    "texts = [review['text'] for review in reviews] # Features\n",
    "stars = [review['stars'] for review in reviews] # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance a dataset to remove over-represented samples\n",
    "\n",
    "from collections import Counter\n",
    "def balance_classes(texts, stars):\n",
    "    freqs = Counter(stars)\n",
    "\n",
    "    # the least common class is the maximum number we want for all classes\n",
    "    maxAllowable = freqs.most_common()[-1][1]\n",
    "    numAdded = {clss: 0 for clss in freqs.keys()}\n",
    "    newStars = []\n",
    "    newTexts = []\n",
    "    for i, star in enumerate(stars):\n",
    "        if numAdded[star] < maxAllowable:\n",
    "            newStars.append(star)\n",
    "            newTexts.append(texts[i])\n",
    "            numAdded[star] += 1\n",
    "    return newTexts, newStars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_texts, balanced_stars = balance_classes(texts, stars)\n",
    "print(\"Distributions before and after dataset balancing\\nNon-Balanced: {}\\nBalanced: {}\".format(Counter(stars), \n",
    "                                       Counter(balanced_stars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at distributions before and after dataset balancing\n",
    "pre_labels, pre_values = zip(*Counter(stars).items())\n",
    "post_labels, post_values = zip(*Counter(balanced_stars).items())\n",
    "pre_indexes = np.arange(len(pre_labels))\n",
    "post_indexes = np.arange(len(post_labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(pre_indexes, pre_values, width)\n",
    "plt.bar(post_indexes, post_values, width)\n",
    "plt.xticks(pre_indexes + width * 0.5, pre_labels)\n",
    "plt.legend(['Pre-Balance', 'Post-Balance'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pre and post balanced datasets as numpy.save()\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "preBal = TemporaryFile()\n",
    "postBal = TemporaryFile()\n",
    "\n",
    "np.save(preBal, stars)\n",
    "np.save(postBal, balanced_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split files into training and testing sets\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "vectors = vectorizer.fit_transform(balanced_texts)\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, balanced_stars, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Train and Stack ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'], num_units = 128, embedding_size = 16):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Embedding(input_dim = 10000, output_dim = embedding_size, input_length = 1050))\n",
    "    model.add(Bidirectional(LSTM(num_units)))\n",
    "    model.add(Dense(1, activation = 'softmax'))\n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "svm_clf = LinearSVC()\n",
    "lstm_clf = lstm_model()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[svm_clf, lstm_clf],\n",
    "                         meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_clf.fit(X_train, y_train)\n",
    "# lstm_clf.fit(X_train, y_train)\n",
    "# sclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the trained and fitted model on the test set\n",
    "predictions = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model's Accuracy Report of SVM\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classification Report of SVM\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "# Rows: Predictions\n",
    "# Cols: Correct class\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ookubo-experimentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
