{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LOC = 'data/'\n",
    "FILE_NAME = 'data_train.json'\n",
    "\n",
    "# Load in JSON files and extract from JSON\n",
    "reviews_json = open(DATA_LOC + FILE_NAME, 'r')\n",
    "reviews = json.load(reviews_json)\n",
    "\n",
    "# Analyze the distribution of stars and reviews as seperate lists\n",
    "texts = [review['text'] for review in reviews] # Features\n",
    "stars = [review['stars'] for review in reviews] # Labels\n",
    "\n",
    "df = {'Text' : texts, 'Stars' : stars}\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=r['Text'], tags=[r.Stars]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=r['Text'], tags=[r.Stars]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234006/234006 [00:00<00:00, 2813580.69it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234006/234006 [00:00<00:00, 2864633.83it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3123831.70it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3397977.82it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3458260.26it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3112489.07it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3007253.32it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3238756.83it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3258141.44it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 2968192.77it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3289084.12it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3428973.75it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3376527.20it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3273037.50it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3270300.18it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3346913.08it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3465537.85it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3400497.18it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3325176.35it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3459637.72it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3379573.31it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3322159.99it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3176710.31it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3188930.77it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3423089.91it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3359169.77it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3419035.63it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3385016.49it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3334938.13it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3055942.40it/s]\n",
      "100%|██████████| 234006/234006 [00:00<00:00, 3472256.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 57s, sys: 3min 24s, total: 39min 21s\n",
      "Wall time: 18min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oasysokubo/opt/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/oasysokubo/opt/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = teach_vectors(model, train_tagged)\n",
    "y_test, X_test = teach_vectors(model, test_tagged)\n",
    "lr = LogisticRegression(n_jobs=1, C=1e5)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.566363210322169\n",
      "Testing F1 score: 0.5048505185038825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.64      0.60     14754\n",
      "         2.0       0.38      0.09      0.15      8231\n",
      "         3.0       0.41      0.15      0.22     10972\n",
      "         4.0       0.42      0.20      0.27     22039\n",
      "         5.0       0.60      0.92      0.73     44293\n",
      "\n",
      "    accuracy                           0.57    100289\n",
      "   macro avg       0.48      0.40      0.39    100289\n",
      "weighted avg       0.52      0.57      0.50    100289\n",
      "\n",
      "[[ 9441   403   331   553  4026]\n",
      " [ 3210   755   879   873  2514]\n",
      " [ 1742   534  1618  2394  4684]\n",
      " [ 1264   211   876  4354 15334]\n",
      " [ 1173    81   226  2181 40632]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oasysokubo/opt/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nltk_model.sav']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'nltk_model.sav'\n",
    "joblib.dump(lr, filename)\n",
    "# Load the model\n",
    "# loaded_model = joblib.load(filename)\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
